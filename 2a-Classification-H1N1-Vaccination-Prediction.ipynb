{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Survey Data as a Predictor of Pandemic Vaccination\n",
    "## 2a - Classification Modeling\n",
    "\n",
    "### Mark Patterson, March 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to 2a\n",
    "Following EDA, I imported the data into this notebook for additional data preparation, model preprocessing, and initial runs of classification modeling. Eventually, I decided to change some of the data preperation and that, along with further runs of the models are in notebook 2b. That approach, I have named Approach B. \n",
    "\n",
    "This notebook contains runs of Approach A classification modeling - utiliing a pipeline for pre-processign and modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on model evaluation criteria. \n",
    "To evaluate the performacne of each model I will use accuracy, to gauge the overall predictive power of the model. Another important criteria is precision of class 1. Class 1 for our target variable are the respondents that DID get the H1N1 vaccination. Precision of class 1 tells us percentage of people that the model predicted to have goten the vaccination, but in reality had not. This is important as it could mean people that need additional vaccination informaiton may get overlooked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, explained_variance_score, confusion_matrix, accuracy_score, classification_report, log_loss\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Increase column width to display df\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0           0           1.0             0.0                        0.0   \n",
       "1           1           3.0             2.0                        0.0   \n",
       "2           2           1.0             1.0                        0.0   \n",
       "3           3           1.0             1.0                        0.0   \n",
       "4           4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "0                    1.0               0.0                   0.0   \n",
       "1                    1.0               0.0                   0.0   \n",
       "2                    0.0               NaN                   NaN   \n",
       "3                    0.0               0.0                   1.0   \n",
       "4                    1.0               0.0                   0.0   \n",
       "\n",
       "   chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "0                    0.0                   0.0            0.0   \n",
       "1                    0.0                   0.0            0.0   \n",
       "2                    1.0                   0.0            0.0   \n",
       "3                    1.0                   0.0            0.0   \n",
       "4                    0.0                   0.0            0.0   \n",
       "\n",
       "   health_insurance  opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "0               1.0                          3.0                1.0   \n",
       "1               1.0                          5.0                4.0   \n",
       "2               NaN                          3.0                1.0   \n",
       "3               NaN                          3.0                3.0   \n",
       "4               NaN                          3.0                3.0   \n",
       "\n",
       "   opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "0                          2.0                          2.0   \n",
       "1                          4.0                          4.0   \n",
       "2                          1.0                          4.0   \n",
       "3                          5.0                          5.0   \n",
       "4                          2.0                          3.0   \n",
       "\n",
       "   opinion_seas_risk  opinion_seas_sick_from_vacc  age_group  education  race  \\\n",
       "0                1.0                          2.0        3.0        0.0   3.0   \n",
       "1                2.0                          4.0        1.0        1.0   3.0   \n",
       "2                1.0                          2.0        0.0        3.0   3.0   \n",
       "3                4.0                          1.0        4.0        1.0   3.0   \n",
       "4                1.0                          4.0        2.0        2.0   3.0   \n",
       "\n",
       "   sex  income_poverty  marital_status  rent_or_own  employment_status  \\\n",
       "0  0.0             0.0             0.0          1.0                1.0   \n",
       "1  1.0             0.0             0.0          0.0                2.0   \n",
       "2  1.0             1.0             0.0          1.0                2.0   \n",
       "3  0.0             0.0             0.0          0.0                1.0   \n",
       "4  0.0             1.0             1.0          1.0                2.0   \n",
       "\n",
       "   hhs_geo_region  census_msa  household_adults  household_children  \\\n",
       "0             8.0         2.0               0.0                 0.0   \n",
       "1             1.0         0.0               0.0                 0.0   \n",
       "2             9.0         0.0               2.0                 0.0   \n",
       "3             5.0         1.0               0.0                 0.0   \n",
       "4             9.0         0.0               1.0                 0.0   \n",
       "\n",
       "   employment_industry  h1n1_vaccine  seasonal_vaccine  \n",
       "0                  NaN             0                 0  \n",
       "1                  3.0             0                 1  \n",
       "2                  9.0             0                 0  \n",
       "3                  NaN             0                 1  \n",
       "4                  1.0             0                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df_7 = pd.read_csv('data/df_5.csv')\n",
    "\n",
    "# print the shape\n",
    "print(df_7.shape)\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21033\n",
      "1     5674\n",
      "Name: h1n1_vaccine, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    78.754634\n",
       "1    21.245366\n",
       "Name: h1n1_vaccine, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_7['h1n1_vaccine'].value_counts())\n",
    "df_7['h1n1_vaccine'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Modelling\n",
    "In early explorations (see other Notebook) a \"dummy classifier\" model was run, and with the \"stratified\" version, accuracy was 0.67. The plan for classification modelling is to test 6 different models: \n",
    "a) Random Forest (to btain feature importances)\n",
    "b) XGBoost (for its power)\n",
    "c) KNN\n",
    "d) Decision Trees\n",
    "e) Logistic Regression\n",
    "f) SVC\n",
    "\n",
    "Grid Search will be used to optimize the parameters of some models. \n",
    "First, all models will be run with h1n1 vaccination as the target variable (Y); and then a second series of models will be run with seasonal vaccination as the target variable (Y2).\n",
    "\n",
    "A pipeline will be constructed to address multiple steps of modeling including: \n",
    "a) Imputing - KNNImputer\n",
    "b) Scaling - StandardScaler\n",
    "c) SMOTE - for h1n1 vaccination set - as there is sizeable class imbalance\n",
    "d) Model - fit and predict\n",
    "e) Results - summary reports and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = df_7.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707,)\n",
      "(26707, 34)\n"
     ]
    }
   ],
   "source": [
    "# Need to split data into X and y dataframes.\n",
    "y = df_8['h1n1_vaccine']\n",
    "X = df_8.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'], axis=1)\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18694, 34)\n",
      "(8013, 34)\n",
      "(18694,)\n",
      "(8013,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test sets. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=34)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run a Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6680394359166355"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dclf = DummyClassifier(strategy='stratified', random_state=15)\n",
    "dclf.fit(X_train, y_train)\n",
    "dclf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run initial classification models (defaults) without SMOTE\n",
    "Initial attempts at running a pipeline that included SMOTE failed. So will first run 6 models in plain default versions using the pipeline. NOTE that this is data preperation A (with 34 variables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a few more libraries\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying a different type of pipeline (B) and see if SMOTE works. Nope... same error message as before.\n",
    "# But it does work without the SMOTE. \n",
    "pipe = make_pipeline(KNNImputer(), StandardScaler(), RandomForestClassifier(random_state=44))\n",
    "pipe = pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842755522276301\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8361412704355422\n"
     ]
    }
   ],
   "source": [
    "# Yet, another version... (C). It runs without an error, BUT it does not appear to actually do the SMOTE (unequal classes still)\n",
    "random_state = 38\n",
    "model3 = Pipeline([\n",
    "        ('imp', KNNImputer()),\n",
    "        ('sca1', StandardScaler()),\n",
    "        ('smote', SMOTE()),\n",
    "        ('classification', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "training_preds = model3.predict(X_train)\n",
    "test_preds = model3.predict(X_test)\n",
    "accuracy_3 = accuracy_score(y_test, y_pred)\n",
    "print(accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: Random Forest with SMOTE\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14645\n",
      "           1       1.00      1.00      1.00      4049\n",
      "\n",
      "    accuracy                           1.00     18694\n",
      "   macro avg       1.00      1.00      1.00     18694\n",
      "weighted avg       1.00      1.00      1.00     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          14645     0  14645\n",
      "1              2  4047   4049\n",
      "All        14647  4047  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      6388\n",
      "           1       0.62      0.48      0.54      1625\n",
      "\n",
      "    accuracy                           0.84      8013\n",
      "   macro avg       0.75      0.70      0.72      8013\n",
      "weighted avg       0.82      0.84      0.83      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5911   477  6388\n",
      "1           841   784  1625\n",
      "All        6752  1261  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get results - one off for the imblearn pipeline. \n",
    "print('--------------------------------------------------------------------------')\n",
    "print('MODEL: Random Forest with SMOTE')\n",
    "print('\\nClassification Report - TRAIN')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(classification_report(y_train, training_preds))\n",
    "print('--------------------------------------------------------------------------')\n",
    "# Confusion Matrix\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Confusion Matrix - TRAIN')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(pd.crosstab(y_train, training_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('--------------------------------------------------------------------------')\n",
    "# Classification Report\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Classification Report - TEST')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(classification_report(y_test, test_preds))\n",
    "print('--------------------------------------------------------------------------')\n",
    "# Confusion Matrix\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Confusion Matrix - TEST')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(pd.crosstab(y_test, test_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print('--------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL RUN 1. \n",
    "# Original Pipeline.. SMOTE step throws an error. So commented it out. Will fallback to running SMOTE as a sept. step.\n",
    "\n",
    "def classif_report (model):\n",
    "    imputer = KNNImputer()\n",
    "    scaler = StandardScaler()\n",
    "#     xmoter = SMOTE()\n",
    "    pipeline = Pipeline(steps=[('i', imputer), ('s', scaler), ('m', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    training_preds = pipeline.predict(X_train)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "\n",
    "    # Get results\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(f'MODEL: {model}')\n",
    "    print('\\nClassification Report - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, training_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_train, training_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Classification Report\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Classification Report - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, test_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_test, test_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: RandomForestClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14645\n",
      "           1       1.00      1.00      1.00      4049\n",
      "\n",
      "    accuracy                           1.00     18694\n",
      "   macro avg       1.00      1.00      1.00     18694\n",
      "weighted avg       1.00      1.00      1.00     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          14645     0  14645\n",
      "1              0  4049   4049\n",
      "All        14645  4049  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91      6388\n",
      "           1       0.68      0.41      0.51      1625\n",
      "\n",
      "    accuracy                           0.84      8013\n",
      "   macro avg       0.77      0.68      0.71      8013\n",
      "weighted avg       0.83      0.84      0.82      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0    1   All\n",
      "True                      \n",
      "0          6079  309  6388\n",
      "1           964  661  1625\n",
      "All        7043  970  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doctor_recc_h1n1</td>\n",
       "      <td>0.111224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employment_industry</td>\n",
       "      <td>0.072995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>opinion_h1n1_risk</td>\n",
       "      <td>0.068024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opinion_h1n1_vacc_effective</td>\n",
       "      <td>0.062342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hhs_geo_region</td>\n",
       "      <td>0.054741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opinion_seas_risk</td>\n",
       "      <td>0.045590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_group</td>\n",
       "      <td>0.037457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>opinion_h1n1_sick_from_vacc</td>\n",
       "      <td>0.033034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>education</td>\n",
       "      <td>0.032316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>opinion_seas_vacc_effective</td>\n",
       "      <td>0.031408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>h1n1_concern</td>\n",
       "      <td>0.030971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>opinion_seas_sick_from_vacc</td>\n",
       "      <td>0.030466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>income_poverty</td>\n",
       "      <td>0.029081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>doctor_recc_seasonal</td>\n",
       "      <td>0.028419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>census_msa</td>\n",
       "      <td>0.027187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>household_adults</td>\n",
       "      <td>0.025311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>h1n1_knowledge</td>\n",
       "      <td>0.022620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>household_children</td>\n",
       "      <td>0.022389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>employment_status</td>\n",
       "      <td>0.020372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>0.019283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features  importance\n",
       "0              doctor_recc_h1n1    0.111224\n",
       "1           employment_industry    0.072995\n",
       "2             opinion_h1n1_risk    0.068024\n",
       "3   opinion_h1n1_vacc_effective    0.062342\n",
       "4                hhs_geo_region    0.054741\n",
       "5             opinion_seas_risk    0.045590\n",
       "6                     age_group    0.037457\n",
       "7   opinion_h1n1_sick_from_vacc    0.033034\n",
       "8                     education    0.032316\n",
       "9   opinion_seas_vacc_effective    0.031408\n",
       "10                 h1n1_concern    0.030971\n",
       "11  opinion_seas_sick_from_vacc    0.030466\n",
       "12               income_poverty    0.029081\n",
       "13         doctor_recc_seasonal    0.028419\n",
       "14                   census_msa    0.027187\n",
       "15             household_adults    0.025311\n",
       "16               h1n1_knowledge    0.022620\n",
       "17           household_children    0.022389\n",
       "18            employment_status    0.020372\n",
       "19             health_insurance    0.019283"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at feature importances (RandomForest) - from default / vanilla model (no SMOTE)\n",
    "\n",
    "importance = pd.DataFrame(data={'features': X_train.columns, 'importance': model.feature_importances_})\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance = importance.reset_index()\n",
    "importance.drop('index', axis=1, inplace=True)\n",
    "importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: KNeighborsClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     14645\n",
      "           1       0.75      0.50      0.60      4049\n",
      "\n",
      "    accuracy                           0.86     18694\n",
      "   macro avg       0.81      0.73      0.76     18694\n",
      "weighted avg       0.85      0.86      0.84     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          13949   696  14645\n",
      "1           2005  2044   4049\n",
      "All        15954  2740  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      6388\n",
      "           1       0.54      0.38      0.44      1625\n",
      "\n",
      "    accuracy                           0.81      8013\n",
      "   macro avg       0.70      0.65      0.66      8013\n",
      "weighted avg       0.79      0.81      0.80      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5874   514  6388\n",
      "1          1013   612  1625\n",
      "All        6887  1126  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = KNeighborsClassifier()\n",
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: XGBClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     14645\n",
      "           1       0.72      0.49      0.58      4049\n",
      "\n",
      "    accuracy                           0.85     18694\n",
      "   macro avg       0.79      0.72      0.74     18694\n",
      "weighted avg       0.84      0.85      0.84     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          13865   780  14645\n",
      "1           2070  1979   4049\n",
      "All        15935  2759  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.91      6388\n",
      "           1       0.68      0.47      0.55      1625\n",
      "\n",
      "    accuracy                           0.85      8013\n",
      "   macro avg       0.78      0.71      0.73      8013\n",
      "weighted avg       0.83      0.85      0.84      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          6027   361  6388\n",
      "1           866   759  1625\n",
      "All        6893  1120  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = XGBClassifier()\n",
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: DecisionTreeClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14645\n",
      "           1       1.00      1.00      1.00      4049\n",
      "\n",
      "    accuracy                           1.00     18694\n",
      "   macro avg       1.00      1.00      1.00     18694\n",
      "weighted avg       1.00      1.00      1.00     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          14645     0  14645\n",
      "1              0  4049   4049\n",
      "All        14645  4049  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84      6388\n",
      "           1       0.40      0.46      0.43      1625\n",
      "\n",
      "    accuracy                           0.75      8013\n",
      "   macro avg       0.63      0.64      0.63      8013\n",
      "weighted avg       0.76      0.75      0.76      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5281  1107  6388\n",
      "1           885   740  1625\n",
      "All        6166  1847  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = DecisionTreeClassifier()\n",
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: LogisticRegression()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90     14645\n",
      "           1       0.67      0.43      0.52      4049\n",
      "\n",
      "    accuracy                           0.83     18694\n",
      "   macro avg       0.77      0.68      0.71     18694\n",
      "weighted avg       0.82      0.83      0.82     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          13812   833  14645\n",
      "1           2324  1725   4049\n",
      "All        16136  2558  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      6388\n",
      "           1       0.66      0.42      0.51      1625\n",
      "\n",
      "    accuracy                           0.84      8013\n",
      "   macro avg       0.76      0.68      0.71      8013\n",
      "weighted avg       0.82      0.84      0.82      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          6037   351  6388\n",
      "1           943   682  1625\n",
      "All        6980  1033  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = LogisticRegression()\n",
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: SVC()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     14645\n",
      "           1       0.80      0.51      0.62      4049\n",
      "\n",
      "    accuracy                           0.87     18694\n",
      "   macro avg       0.84      0.74      0.77     18694\n",
      "weighted avg       0.86      0.87      0.85     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          14136   509  14645\n",
      "1           1986  2063   4049\n",
      "All        16122  2572  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      6388\n",
      "           1       0.67      0.42      0.52      1625\n",
      "\n",
      "    accuracy                           0.84      8013\n",
      "   macro avg       0.77      0.69      0.71      8013\n",
      "weighted avg       0.83      0.84      0.83      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          6056   332  6388\n",
      "1           936   689  1625\n",
      "All        6992  1021  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = SVC()\n",
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on the first 6 models - dat prep A with no SMOTE (34 variables)\n",
    "Accuracy was about equal across most models at 0.84. XGBoost had the best precision (class 1) score at 0.68. Decision Trees performed worst at accuracy of 0.0.75 and precision of 0.40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconfigure things for SMOTE\n",
    "Tried using SMOTE as part of the pipeline. Had some issues getting it to run. Tried doing a seperate preprocessing pipeline, but then had issues figuring out how to feed that into a seperate SMOTE step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42475416,  1.19594035, -0.22565807, ..., -1.18156013,\n",
       "         0.49172474, -1.55273258],\n",
       "       [ 1.52458714, -0.42438383, -0.22565807, ..., -1.18156013,\n",
       "        -0.58271974,  0.56911297],\n",
       "       [-0.67507883, -0.42438383, -0.22565807, ...,  2.80800331,\n",
       "         0.49172474, -1.23124083],\n",
       "       ...,\n",
       "       [ 1.52458714, -0.42438383, -0.22565807, ...,  0.14829435,\n",
       "        -0.58271974, -1.23124083],\n",
       "       [ 0.42475416,  1.19594035, -0.22565807, ...,  1.47814883,\n",
       "        -0.58271974,  0.44051627],\n",
       "       [ 0.42475416, -0.42438383, -0.22565807, ...,  0.14829435,\n",
       "         0.49172474, -1.55273258]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing pipeline\n",
    "imputer = KNNImputer()\n",
    "scaler = StandardScaler()\n",
    "pipe_pre = make_pipeline(imputer, scaler)\n",
    "# x_train = pipe_pre.fit_transform(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '0': 14645\n",
      "Before OverSampling, counts of label '1': 4049\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-3af90d0179de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'After OverSampling, the shape of train_X: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         X, y = self._validate_data(\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 646\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/markp/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n\u001b[0;32m--> 100\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Address the target class imbalance with SMOTE - as a seperate step. Not sure how to get the output of pre-pipe?\n",
    "\n",
    "print(\"Before OverSampling, counts of label '0': {}\".format(sum(y_train == 0))) \n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "\n",
    "sm = SMOTE(random_state = 3) \n",
    "X_train_s, y_train_s = sm.fit_sample(X_train, y_train) \n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_s.shape)) \n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_s.shape)) \n",
    "\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_s == 0))) \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_s == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another attempt at a pipeline with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the Pipeline (no error messages from SMOTE, BUT not applying it either?\n",
    "\n",
    "def classif_report1 (model):\n",
    "    imputer = KNNImputer()\n",
    "    scaler = StandardScaler()\n",
    "    xmoter = SMOTE()\n",
    "    pipeline = Pipeline(steps=[('i', imputer), ('s', scaler), ('xm', xmoter),('m', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    training_preds = pipeline.predict(X_train)\n",
    "    test_preds = pipeline.predict(X_test)\n",
    "\n",
    "    # Get results\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(f'MODEL: {model}')\n",
    "    print('\\nClassification Report - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, training_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_train, training_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Classification Report\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Classification Report - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y_test, test_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y_test, test_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: KNeighborsClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.84     14645\n",
      "           1       0.50      0.96      0.66      4049\n",
      "\n",
      "    accuracy                           0.79     18694\n",
      "   macro avg       0.74      0.85      0.75     18694\n",
      "weighted avg       0.88      0.79      0.80     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          10805  3840  14645\n",
      "1            151  3898   4049\n",
      "All        10956  7738  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75      6388\n",
      "           1       0.34      0.71      0.46      1625\n",
      "\n",
      "    accuracy                           0.66      8013\n",
      "   macro avg       0.62      0.68      0.61      8013\n",
      "weighted avg       0.78      0.66      0.69      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          4132  2256  6388\n",
      "1           471  1154  1625\n",
      "All        4603  3410  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report1 (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: XGBClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90     14645\n",
      "           1       0.64      0.56      0.60      4049\n",
      "\n",
      "    accuracy                           0.84     18694\n",
      "   macro avg       0.76      0.74      0.75     18694\n",
      "weighted avg       0.83      0.84      0.83     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0          13368  1277  14645\n",
      "1           1773  2276   4049\n",
      "All        15141  3553  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      6388\n",
      "           1       0.60      0.53      0.56      1625\n",
      "\n",
      "    accuracy                           0.83      8013\n",
      "   macro avg       0.74      0.72      0.73      8013\n",
      "weighted avg       0.83      0.83      0.83      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          5801   587  6388\n",
      "1           762   863  1625\n",
      "All        6563  1450  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report1 (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models for Seasonal Vaccination Target\n",
    "Will use the seasonal vaccination as the target, so need to reassign Y, and then run the 3 models.. classes are fairly balanced, so for this data, SMOTE is not necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707, 37)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0           0           1.0             0.0                        0.0   \n",
       "1           1           3.0             2.0                        0.0   \n",
       "2           2           1.0             1.0                        0.0   \n",
       "3           3           1.0             1.0                        0.0   \n",
       "4           4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "0                    1.0               0.0                   0.0   \n",
       "1                    1.0               0.0                   0.0   \n",
       "2                    0.0               NaN                   NaN   \n",
       "3                    0.0               0.0                   1.0   \n",
       "4                    1.0               0.0                   0.0   \n",
       "\n",
       "   chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "0                    0.0                   0.0            0.0   \n",
       "1                    0.0                   0.0            0.0   \n",
       "2                    1.0                   0.0            0.0   \n",
       "3                    1.0                   0.0            0.0   \n",
       "4                    0.0                   0.0            0.0   \n",
       "\n",
       "   health_insurance  opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "0               1.0                          3.0                1.0   \n",
       "1               1.0                          5.0                4.0   \n",
       "2               NaN                          3.0                1.0   \n",
       "3               NaN                          3.0                3.0   \n",
       "4               NaN                          3.0                3.0   \n",
       "\n",
       "   opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "0                          2.0                          2.0   \n",
       "1                          4.0                          4.0   \n",
       "2                          1.0                          4.0   \n",
       "3                          5.0                          5.0   \n",
       "4                          2.0                          3.0   \n",
       "\n",
       "   opinion_seas_risk  opinion_seas_sick_from_vacc  age_group  education  race  \\\n",
       "0                1.0                          2.0        3.0        0.0   3.0   \n",
       "1                2.0                          4.0        1.0        1.0   3.0   \n",
       "2                1.0                          2.0        0.0        3.0   3.0   \n",
       "3                4.0                          1.0        4.0        1.0   3.0   \n",
       "4                1.0                          4.0        2.0        2.0   3.0   \n",
       "\n",
       "   sex  income_poverty  marital_status  rent_or_own  employment_status  \\\n",
       "0  0.0             0.0             0.0          1.0                1.0   \n",
       "1  1.0             0.0             0.0          0.0                2.0   \n",
       "2  1.0             1.0             0.0          1.0                2.0   \n",
       "3  0.0             0.0             0.0          0.0                1.0   \n",
       "4  0.0             1.0             1.0          1.0                2.0   \n",
       "\n",
       "   hhs_geo_region  census_msa  household_adults  household_children  \\\n",
       "0             8.0         2.0               0.0                 0.0   \n",
       "1             1.0         0.0               0.0                 0.0   \n",
       "2             9.0         0.0               2.0                 0.0   \n",
       "3             5.0         1.0               0.0                 0.0   \n",
       "4             9.0         0.0               1.0                 0.0   \n",
       "\n",
       "   employment_industry  h1n1_vaccine  seasonal_vaccine  \n",
       "0                  NaN             0                 0  \n",
       "1                  3.0             0                 1  \n",
       "2                  9.0             0                 0  \n",
       "3                  NaN             0                 1  \n",
       "4                  1.0             0                 0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_7.shape)\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 36)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_9 = df_7.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df_9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    14272\n",
      "1    12435\n",
      "Name: seasonal_vaccine, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    53.439173\n",
       "1    46.560827\n",
       "Name: seasonal_vaccine, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_9['seasonal_vaccine'].value_counts())\n",
    "df_9['seasonal_vaccine'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26707,)\n",
      "(26707, 34)\n"
     ]
    }
   ],
   "source": [
    "# Need to split data into X and y dataframes.\n",
    "y1 = df_9['seasonal_vaccine']\n",
    "X1 = df_9.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'], axis=1)\n",
    "print(y1.shape)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18694, 34)\n",
      "(8013, 34)\n",
      "(18694,)\n",
      "(8013,)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test sets. \n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.30, random_state=35)\n",
    "print(X1_train.shape)\n",
    "print(X1_test.shape)\n",
    "\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49831523773867464"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN a DUMMY Classifier as a baseline\n",
    "dclf = DummyClassifier(strategy='stratified', random_state=16)\n",
    "dclf.fit(X1_train, y1_train)\n",
    "dclf.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run classification models (target = seasonal vacc) - data prep A. \n",
    "This run of models uses the \"classif_report\" function to run the pipeline. \n",
    "A) KNN\n",
    "B) XGBoost\n",
    "C) Random Forest (plus feature importance)\n",
    "D) Decion Trees\n",
    "E) Logistic Regression\n",
    "F) SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the Pipeline\n",
    "\n",
    "def classif_report (model):\n",
    "    imputer = KNNImputer()\n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline(steps=[('i', imputer), ('s', scaler), ('m', model)])\n",
    "    pipeline.fit(X1_train, y1_train)\n",
    "\n",
    "    training_preds = pipeline.predict(X1_train)\n",
    "    test_preds = pipeline.predict(X1_test)\n",
    "\n",
    "    # Get results\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(f'MODEL: {model}')\n",
    "    print('\\nClassification Report - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y1_train, training_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TRAIN')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y1_train, training_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Classification Report\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Classification Report - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(classification_report(y1_test, test_preds))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    # Confusion Matrix\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('Confusion Matrix - TEST')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print(pd.crosstab(y1_test, test_preds, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: KNeighborsClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      9946\n",
      "           1       0.81      0.79      0.80      8748\n",
      "\n",
      "    accuracy                           0.81     18694\n",
      "   macro avg       0.81      0.81      0.81     18694\n",
      "weighted avg       0.81      0.81      0.81     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0           8278  1668   9946\n",
      "1           1837  6911   8748\n",
      "All        10115  8579  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74      4326\n",
      "           1       0.69      0.68      0.68      3687\n",
      "\n",
      "    accuracy                           0.71      8013\n",
      "   macro avg       0.71      0.71      0.71      8013\n",
      "weighted avg       0.71      0.71      0.71      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3204  1122  4326\n",
      "1          1183  2504  3687\n",
      "All        4387  3626  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: XGBClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81      9946\n",
      "           1       0.79      0.76      0.77      8748\n",
      "\n",
      "    accuracy                           0.79     18694\n",
      "   macro avg       0.79      0.79      0.79     18694\n",
      "weighted avg       0.79      0.79      0.79     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0           8154  1792   9946\n",
      "1           2080  6668   8748\n",
      "All        10234  8460  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4326\n",
      "           1       0.77      0.75      0.76      3687\n",
      "\n",
      "    accuracy                           0.78      8013\n",
      "   macro avg       0.78      0.78      0.78      8013\n",
      "weighted avg       0.78      0.78      0.78      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3499   827  4326\n",
      "1           925  2762  3687\n",
      "All        4424  3589  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try and so some grid search on XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.3],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_child_weight': [3, 5],\n",
    "    'subsample': [0.5, 0.8],\n",
    "    'n_estimators': [50],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "learning_rate: 0.1\n",
      "max_depth: 5\n",
      "min_child_weight: 5\n",
      "n_estimators: 50\n",
      "subsample: 0.8\n",
      "---------------------------------------------\n",
      "XGBClassifier(max_depth=5, min_child_weight=5, n_estimators=50, subsample=0.8)\n",
      "\n",
      "Training Accuracy: 80.05%\n",
      "Validation accuracy: 78.52%\n"
     ]
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, n_jobs=1)\n",
    "grid_clf.fit(X1_train, y1_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "print('---------------------------------------------')\n",
    "print(grid_clf.best_estimator_)\n",
    "\n",
    "training_preds = grid_clf.predict(X1_train)\n",
    "test_preds = grid_clf.predict(X1_test)\n",
    "training_accuracy = accuracy_score(y1_train, training_preds)\n",
    "test_accuracy = accuracy_score(y1_test, test_preds)\n",
    "\n",
    "print('')\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2 at GridSearchCV on XGBoost\n",
    "# Set-up the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [4, 7],\n",
    "    'min_child_weight': [4, 5],\n",
    "    'subsample': [0.6, 0.8],\n",
    "    'n_estimators': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "learning_rate: 0.1\n",
      "max_depth: 4\n",
      "min_child_weight: 4\n",
      "n_estimators: 100\n",
      "subsample: 0.6\n",
      "---------------------------------------------\n",
      "XGBClassifier(max_depth=4, min_child_weight=4, subsample=0.6)\n",
      "\n",
      "Training Accuracy: 80.15%\n",
      "Validation accuracy: 78.57%\n"
     ]
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, n_jobs=1)\n",
    "grid_clf.fit(X1_train, y1_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print('Grid Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "print('---------------------------------------------')\n",
    "print(grid_clf.best_estimator_)\n",
    "\n",
    "training_preds = grid_clf.predict(X1_train)\n",
    "test_preds = grid_clf.predict(X1_test)\n",
    "training_accuracy = accuracy_score(y1_train, training_preds)\n",
    "test_accuracy = accuracy_score(y1_test, test_preds)\n",
    "\n",
    "print('')\n",
    "print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "print('Validation accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: RandomForestClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9946\n",
      "           1       1.00      1.00      1.00      8748\n",
      "\n",
      "    accuracy                           1.00     18694\n",
      "   macro avg       1.00      1.00      1.00     18694\n",
      "weighted avg       1.00      1.00      1.00     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1    All\n",
      "True                        \n",
      "0          9946     0   9946\n",
      "1             0  8748   8748\n",
      "All        9946  8748  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      4326\n",
      "           1       0.76      0.74      0.75      3687\n",
      "\n",
      "    accuracy                           0.77      8013\n",
      "   macro avg       0.77      0.77      0.77      8013\n",
      "weighted avg       0.77      0.77      0.77      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3473   853  4326\n",
      "1           960  2727  3687\n",
      "All        4433  3580  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opinion_seas_risk</td>\n",
       "      <td>0.098468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opinion_seas_vacc_effective</td>\n",
       "      <td>0.088989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doctor_recc_seasonal</td>\n",
       "      <td>0.085048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employment_industry</td>\n",
       "      <td>0.065018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_group</td>\n",
       "      <td>0.060375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hhs_geo_region</td>\n",
       "      <td>0.049494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>opinion_h1n1_vacc_effective</td>\n",
       "      <td>0.033921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>opinion_h1n1_risk</td>\n",
       "      <td>0.033715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>education</td>\n",
       "      <td>0.031279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>opinion_seas_sick_from_vacc</td>\n",
       "      <td>0.030675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>income_poverty</td>\n",
       "      <td>0.029536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>opinion_h1n1_sick_from_vacc</td>\n",
       "      <td>0.028192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h1n1_concern</td>\n",
       "      <td>0.028158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>health_insurance</td>\n",
       "      <td>0.025172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>census_msa</td>\n",
       "      <td>0.024687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>household_adults</td>\n",
       "      <td>0.023794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>h1n1_knowledge</td>\n",
       "      <td>0.022410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>household_children</td>\n",
       "      <td>0.021476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doctor_recc_h1n1</td>\n",
       "      <td>0.021177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>employment_status</td>\n",
       "      <td>0.020544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features  importance\n",
       "0             opinion_seas_risk    0.098468\n",
       "1   opinion_seas_vacc_effective    0.088989\n",
       "2          doctor_recc_seasonal    0.085048\n",
       "3           employment_industry    0.065018\n",
       "4                     age_group    0.060375\n",
       "5                hhs_geo_region    0.049494\n",
       "6   opinion_h1n1_vacc_effective    0.033921\n",
       "7             opinion_h1n1_risk    0.033715\n",
       "8                     education    0.031279\n",
       "9   opinion_seas_sick_from_vacc    0.030675\n",
       "10               income_poverty    0.029536\n",
       "11  opinion_h1n1_sick_from_vacc    0.028192\n",
       "12                 h1n1_concern    0.028158\n",
       "13             health_insurance    0.025172\n",
       "14                   census_msa    0.024687\n",
       "15             household_adults    0.023794\n",
       "16               h1n1_knowledge    0.022410\n",
       "17           household_children    0.021476\n",
       "18             doctor_recc_h1n1    0.021177\n",
       "19            employment_status    0.020544"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at feature importances - from default / vanilla model\n",
    "\n",
    "importance = pd.DataFrame(data={'features': X1_train.columns, 'importance': model.feature_importances_})\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance = importance.reset_index()\n",
    "importance.drop('index', axis=1, inplace=True)\n",
    "importance.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: DecisionTreeClassifier()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9946\n",
      "           1       1.00      1.00      1.00      8748\n",
      "\n",
      "    accuracy                           1.00     18694\n",
      "   macro avg       1.00      1.00      1.00     18694\n",
      "weighted avg       1.00      1.00      1.00     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1    All\n",
      "True                        \n",
      "0          9946     0   9946\n",
      "1             0  8748   8748\n",
      "All        9946  8748  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.69      4326\n",
      "           1       0.64      0.65      0.64      3687\n",
      "\n",
      "    accuracy                           0.67      8013\n",
      "   macro avg       0.67      0.67      0.67      8013\n",
      "weighted avg       0.67      0.67      0.67      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          2978  1348  4326\n",
      "1          1295  2392  3687\n",
      "All        4273  3740  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: LogisticRegression()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      9946\n",
      "           1       0.77      0.74      0.76      8748\n",
      "\n",
      "    accuracy                           0.78     18694\n",
      "   macro avg       0.78      0.77      0.77     18694\n",
      "weighted avg       0.78      0.78      0.78     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0           8022  1924   9946\n",
      "1           2272  6476   8748\n",
      "All        10294  8400  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79      4326\n",
      "           1       0.76      0.73      0.75      3687\n",
      "\n",
      "    accuracy                           0.77      8013\n",
      "   macro avg       0.77      0.77      0.77      8013\n",
      "weighted avg       0.77      0.77      0.77      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3496   830  4326\n",
      "1           990  2697  3687\n",
      "All        4486  3527  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the model... change this for each model to run. \n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "MODEL: SVC()\n",
      "\n",
      "Classification Report - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      9946\n",
      "           1       0.83      0.81      0.82      8748\n",
      "\n",
      "    accuracy                           0.83     18694\n",
      "   macro avg       0.83      0.83      0.83     18694\n",
      "weighted avg       0.83      0.83      0.83     18694\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TRAIN\n",
      "--------------------------------------------------------------------------\n",
      "Predicted      0     1    All\n",
      "True                         \n",
      "0           8495  1451   9946\n",
      "1           1646  7102   8748\n",
      "All        10141  8553  18694\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Classification Report - TEST\n",
      "--------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      4326\n",
      "           1       0.76      0.74      0.75      3687\n",
      "\n",
      "    accuracy                           0.77      8013\n",
      "   macro avg       0.77      0.77      0.77      8013\n",
      "weighted avg       0.77      0.77      0.77      8013\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "Confusion Matrix - TEST\n",
      "--------------------------------------------------------------------------\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3463   863  4326\n",
      "1           954  2733  3687\n",
      "All        4417  3596  8013\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Run the function with the assigned model above. \n",
    "classif_report (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations on the models run on target - seasonal vaccination\n",
    "About 4 of these models had similar accuracy rates, but the best was XGBoost at 0.78, with precision for class 1 at 0.77. The accuracy is lower than was seen for the h1n1 target variable, and my guess is that this is due to the fact that the seasonal target classes are balanced and perhaps not as prone to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melody grid search example:\n",
    "grid_xgb2 = GridSearchCV(xgb_clf, xgb_param_grid2, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_xgb2.fit(X_train_encoded_cleaned_SMOTE, y_train_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual pieces of pre-processing for reference:\n",
    "\n",
    "# KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "raw5 = pd.DataFrame(imputer.fit_transform(raw5),columns = raw5.columns)\n",
    "\n",
    "# Scaler\n",
    "scale = StandardScaler().fit(X_train)\n",
    "\n",
    "# SMOTE\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train, y_train = sm.fit_sample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example of pipeline with SMOTE as part... different type of pipeline.\n",
    "from imblearn.pipeline import Pipeline\n",
    "model = Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "grid = GridSearchCV(model, params, ...)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yet, another version... \n",
    "random_state = 38\n",
    "model = Pipeline([\n",
    "        ('posFeat1', featureVECTOR()),\n",
    "        ('sca1', StandardScaler()),\n",
    "\n",
    "        # Original SMOTE class\n",
    "        ('smote', SMOTE(random_state=random_state)),\n",
    "        ('classification', SGDClassifier(loss='hinge', max_iter=1, random_state=random_state, tol=None))\n",
    "    ])\n",
    "\n",
    "# Not sure about the bottom part here... \n",
    "model.fit(train_df, train_df['label'].values.tolist())\n",
    "predicted = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And one more example\n",
    "\n",
    "pipe = make_pipeline(SMOTE(random_state=42), StandardScaler(), LinearSVC(dual=False, random_state=13))\n",
    "pipe = pipe.fit(X_train, np.array(y_train))\n",
    "y_pred = pipe.predict(X_test)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example pipeline with some grid search\n",
    "\n",
    "sel = SelectFromModel(ExtraTreesClassifier(n_estimators=10, random_state=444), \n",
    "                      threshold='mean')\n",
    "clf = RandomForestClassifier(n_estimators=5000, random_state=444)\n",
    "\n",
    "model = Pipeline([('sel', sel), ('clf', clf)])\n",
    "params = {'clf__max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "gs = GridSearchCV(model, params)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# How well do your hyperparameter optimizations generalize\n",
    "# to unseen test data?\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
